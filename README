This is a proof-of-concept and so far can handle very basic 
fetch/filter/output pipelines.

Design
------
The Yahoo pipelines are translated into pipelines of Python generators which 
should give a close match to the original data flow. Each call to the final
generator will ripple through the pipeline issuing .next() calls until the 
source is exhausted.

The modules are topologically sorted to give their creation order. 
The main output and inputs are connected via the yielded values and the 
first parameter. Other inputs are passed as named parameters referencing the 
input module.

The JSON representation of the configuration parameters maps closely onto 
Python dictionaries and so is left as-is and passed and parsed as-and-when 
needed.

Each Yahoo module is coded as a separate Python module. This might help in
future if the generators are made to run on separate processors/machines and 
we could use queues to plumb them together.


Install the dependencies
------------------------
Universal feedparser (http://www.feedparser.org/):
  
  * sudo aptitude install python-feedparser 
    (or build from source: http://code.google.com/p/feedparser/downloads)
  
If using a Python version before 2.6 then simplejson is needed:
  
  * http://pypi.python.org/pypi/simplejson


Setting up the environment
--------------------------
Put the source code in a directory, say, pipeline/pipe2py.

Make the package available to Python, e.g.

  export PYTHONPATH=pipeline


Unit tests
----------
Run in the test directory:

  python testbasics.py

  
Usage
-----
There are two ways to compile a Yahoo pipe into Python. One outputs a Python 
script which wraps the pipeline in a function and can then be imported and 
run from another Python program. The other interprets the pipeline on-the-fly 
and executes it within the current process.

1. Compiling a pipeline to a Python script
------------------------------------------
Both of the following will create a python file named after the input argument 
with a .py extension. This can then be run directly or imported into other
pipelines:

  * python compile.py -p pipelineid
  
  or
  
  * python compile.py -f pipelinefile
  
Subpiplines are expected to be contained in python files named pipe_PIPEID.py,
where PIPEID is the Yahoo ID for the pipeline, e.g.
  pipe_2de0e4517ed76082dcddf66f7b218057.py
So if you do use the -f option you should store your pipeline definitions in 
files named the same way, e.g.
  pipe_2de0e4517ed76082dcddf66f7b218057.json
then compile.py will output files with the expected naming convention.
  
2. Interpreting a pipeline and executing in-process
---------------------------------------------------
from pipe2py.compile import parse_and_build_pipe

pipe_def = """json representation of the pipe"""

p = parse_and_build_pipe(pipe_def)

for i in p:
    print i

